[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Solutions to prescreening tasks for Data scientist position",
    "section": "",
    "text": "This web application presents solutions to the prescreening tasks for a Data Scientist position at Health Data Unit, Applied Research Centre, Metrosert.\nTasks\n1.Write bash script to split data into separate files based on gender and weight class.\n2.Impute missing data.\n3.Perform cluster analyses: do samples cluster by sex?\n4.Train a suitable machine learning tool to predict obesity using the dataset and describe performance of the trained model."
  },
  {
    "objectID": "dataset.html",
    "href": "dataset.html",
    "title": "Dataset",
    "section": "",
    "text": "The obesity dataset contains information about participants’ body measurements (e.g., height, weight) and lifestyle (e.g., smaoking, exercising).\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# reading data file\ndf  = pd.read_csv('obesity.data.txt', sep='\\t')\n\nprint('Number of instances:',df.shape[0])\nprint('Number of attributes:',df.shape[1])\n\n\nNumber of instances: 2111\nNumber of attributes: 17\n\n\n\n\nCode\nprint('Attributes:',list(df.columns))\n\n\nAttributes: ['Gender', 'Age', 'Height', 'Weight', 'FHO', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'WeightClass']\n\n\nThe following list offers information over data types of attributes in obesity dataset, and also offers the meaning of encoded attributes.\n\nGender {Female,Male}\nAge numeric\nHeight numeric\nWeight numeric\nFHO (Has a family member suffered or suffers from overweight?) {yes,no}\nFAVC (Do you eat high caloric food frequently?) {yes,no}\nFCVC (Do you usually eat vegetables in your meals?) numeric\nNCP (How many main meals do you have daily?) numeric\nCAEC (Do you eat any food between meals?) {no,Sometimes,Frequently,Always}\nSMOKE (Do you smoke?) {yes,no}\nCH2O (How much water do you drink daily?) numeric\nSCC (Do you monitor the calories you eat daily?) {yes,no}\nFAF (How often do you have physical activity?) numeric\nTUE (How much time do you use technological devices such as cell phone, videogames, television, computer and others?) numeric\nCALC (how often do you drink alcohol?) {no,Sometimes,Frequently,Always}\nMTRANS (Which transportation do you usually use?)\n\n\n1 Checking missing values\nFigure 1 shows the attributes with missing values. The dataset has missing values for most of the attributes, having missing values in the range of 20%-30%.\n\n\nCode\n# number of instances\nsize = df.shape[0]\n\n# get number of missing values per attributes in descending order\ndf_nan = df.isna().sum().sort_values(ascending=False).to_frame()\ndf_nan.columns = ['missing']\n\n# filtering attributes which have missing values\ndf_nan = df_nan[df_nan['missing'] &gt; 0]\ndf_nan['missing_per'] = df_nan['missing']*100//size\ndf_nan['features'] = df_nan.index\n\n\n\n\nCode\n# plotting missing values\n\n\nplt.figure(figsize=(8,4))\nsns.barplot(data=df_nan,x='features',y='missing_per')\nplt.ylabel('% of missing values')\nplt.xticks(rotation=90)\nplt.title('Attribute wise missing values')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Missing values in the dataset\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAll attributes except Gender and WeightClass have missing values."
  },
  {
    "objectID": "task-3.html",
    "href": "task-3.html",
    "title": "Performing cluster analysis",
    "section": "",
    "text": "The task is to Perform cluster analyses: do samples cluster by sex?.\nShow the code\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom sklearn.base import TransformerMixin\n\ndata = pd.read_csv('obesity.data.txt', sep='\\t')\n\nX = data.drop(['WeightClass'], axis=1)\ny = data['WeightClass']"
  },
  {
    "objectID": "task-3.html#gender-distribution-in-clusters",
    "href": "task-3.html#gender-distribution-in-clusters",
    "title": "Performing cluster analysis",
    "section": "3.1 Gender distribution in clusters",
    "text": "3.1 Gender distribution in clusters\nFigure 3 shows the gender distribution in the resultant clusters. Cluster 1 has more male participants, while Cluster 2 has a high number of female participants. Cluster-3 has a comparatively more balanced gender distribution than cluster-1 and cluster-2.\n\n\nShow the code\nsns.countplot(cluster_df, hue='Gender',x='cluster_label')\nplt.title('Gender distribution in clusters')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: Clusters after PCA\n\n\n\n\n\nThe analysis result of clustering with 2 clusters is shown in Figure 4. The figure clearly shows that the two clusters are heavily skewed in terms of gender distribution.\n\n\nShow the code\nmodel = KMeans(n_clusters=2, n_init='auto')\n\ncluster_labels = model.fit_predict(X_)\ncluster_df = pd.DataFrame({'component-1':list(X_[:,0]),\n                           'component-2':list(X_[:,1]),\n                           'cluster_label':list(cluster_labels),\n                           'Gender':X['Gender'],\n                            'Class':data['WeightClass']})\n\n\n\n\nShow the code\nsns.countplot(cluster_df, hue='Gender',x='cluster_label')\nplt.title('Gender distribution in clusters')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Clusters after PCA\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt can be said that samples are clustered by sex."
  },
  {
    "objectID": "MetroSert Assignment-vis.html",
    "href": "MetroSert Assignment-vis.html",
    "title": "Solutions of Prescreening tasks for Data scientist position",
    "section": "",
    "text": "The provided dataset for the tasks contains information about participants of a study aiming at studying obesity. The dataset contains information participants’ lifestyles and their body measurements.\n\n\nCode\n# opening dataset file\ndata = open('obesity.data.txt')"
  },
  {
    "objectID": "MetroSert Assignment-vis.html#plotting-attributes-with-missing-values",
    "href": "MetroSert Assignment-vis.html#plotting-attributes-with-missing-values",
    "title": "Solutions of Prescreening tasks for Data scientist position",
    "section": "3.1 Plotting attributes with missing values",
    "text": "3.1 Plotting attributes with missing values\nWe will now plot the percentage of missing values for each attribute (except gender and weightclass). This plot can be helpful to see whether discarding of an attribute is preffered over the imputation (in case if the attribute has a significantly higher amount of missing values).\n\n\nCode\n# number of samples\nsize = df.shape[0]\n\n# get number of missing values per attributes in descending order\ndf_nan = df.isna().sum().sort_values(ascending=False).to_frame()\ndf_nan.columns = ['missing']\n\ndf_nan = df_nan[df_nan['missing'] &gt; 0]\ndf_nan['missing_per'] = df_nan['missing']*100//size\ndf_nan['features'] = df_nan.index\n\nplt.figure(figsize=(8,4))\nsns.barplot(data=df_nan,x='features',y='missing_per')\nplt.ylabel('% of missing values')\nplt.xticks(rotation=90)\nplt.title('Attribute wise missing values')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAll attributes except Gender and WeightClass have 20% - 30% missing values.\n\n\n\n\nCode\nsns.countplot(df,x='Gender')\n\n\n\n\n\n\n\n\n\n\n\nCode\ndrink = df.loc[df.Age &lt; 18,['Age','CALC']]\nsns.countplot(drink,x='CALC')\nplt.title('how often do you drink alcohol?')\n\n\nText(0.5, 1.0, 'how often do you drink alcohol?')\n\n\n\n\n\n\n\n\n\n\n\nCode\nsmoke = df.loc[df.Age &lt; 18,['Age','SMOKE']]\nsns.countplot(smoke, x='SMOKE')\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.kdeplot(df,x='Age')"
  },
  {
    "objectID": "MetroSert Assignment-vis.html#imputation-strategy",
    "href": "MetroSert Assignment-vis.html#imputation-strategy",
    "title": "Solutions of Prescreening tasks for Data scientist position",
    "section": "3.2 Imputation strategy",
    "text": "3.2 Imputation strategy\n\n3.2.1 Imputing values for CAEC attribute\nWe will impute this attribute by inserting an additional category of ‘unknown’.\n\n\nCode\n# cleaning\n# It is a categorical attribute\ndf['CAEC_clean'] = df['CAEC'].fillna('unknown')\n\n\n\n\nCode\nsns.countplot(df, x='CAEC', hue='Gender')\nplt.title('Do you eat any food between meals')\n\n\nText(0.5, 1.0, 'Do you eat any food between meals')\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Imputing values for Height\nTo impute this attribute, we can use mean imputation method. However, height likely to be different based on gender. As it can be seen in the below chart that average height of males is higher than the same of females.\n\n\nCode\n# Difference in Height based on gender\nplt.figure()\nsns.boxplot(df, x='Height',y='Gender')\nplt.title('Height for Male/Female')\n\n\nText(0.5, 1.0, 'Height for Male/Female')\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef clean_height(df, default):\n    df['Height_clean'] = default\n    for row in df.iterrows():\n        \n\n\n\n\nCode\ndf['Height_clean'] = df['Height'].apply(clean_height)\n\n\n\n\nCode\n# Difference in Weight based on gender\nplt.figure()\nsns.boxplot(df, x='Weight',y='Gender')\nplt.title('Weight for Male/Female')\n\n\nText(0.5, 1.0, 'Weight for Male/Female')\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.boxplot(df, x='Age',y='Gender')\nplt.title('Age for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.boxplot(df, x='TUE',y='Gender')\nplt.title('Usage time for technological devices for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.boxplot(df, x='FAF',y='Gender')\nplt.title('Physical activity time for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.boxplot(df, x='CH2O',y='Gender')\nplt.title('Drinking water for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.boxplot(df, x='NCP',y='Gender')\nplt.title('Number of meals for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.boxplot(df, x='FCVC',y='Gender')\nplt.title('Vegetable consumption for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.histplot(df, x='Age',hue='WeightClass')\nplt.title('Age for Male/Female')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf['Height_clean'] = df['Height'].fillna(df['Height'].mean())\n\n\n\n\n3.2.3 Imputing values for SCC, FHO, MTRANS, FAVC, SMOKE, CALC\nWe will employ a similar strategy here as we did with CAEC attribute.\n\n\nCode\nplt.figure()\nsns.countplot(df, x='SCC', hue='Gender')\nplt.title('Do you monitor the calories you eat daily?')\n\n\nText(0.5, 1.0, 'Do you monitor the calories you eat daily?')\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.countplot(df, x='FHO', hue='Gender')\nplt.title('Has a family member suffered or suffers from overweight?')\n\n\nText(0.5, 1.0, 'Has a family member suffered or suffers from overweight?')\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.countplot(df, x='MTRANS', hue='Gender')\nplt.title('Which transportation do you usually use?')\nplt.xticks(rotation=90)\n\n\n(array([0, 1, 2, 3, 4]),\n [Text(0, 0, 'Public_Transportation'),\n  Text(1, 0, 'Automobile'),\n  Text(2, 0, 'Walking'),\n  Text(3, 0, 'Motorbike'),\n  Text(4, 0, 'Bike')])\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.countplot(df, x='FAVC', hue='Gender')\nplt.title('Do you eat high caloric food frequently?')\nplt.xticks(rotation=90)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.countplot(df, x='SMOKE', hue='Gender')\nplt.title('Do you smoke?')\nplt.xticks(rotation=90)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure()\nsns.countplot(df, x='CALC', hue='Gender')\nplt.title('how often do you drink alcohol?')\nplt.xticks(rotation=90)\n\n\n(array([0, 1, 2, 3]),\n [Text(0, 0, 'no'),\n  Text(1, 0, 'Sometimes'),\n  Text(2, 0, 'Frequently'),\n  Text(3, 0, 'Always')])\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf['SCC_clean'] = df['SCC'].fillna('unknown')\ndf['FHO_clean'] = df['FHO'].fillna('unknown')\ndf['MTRANS_clean'] = df['MTRANS'].fillna('unknown')\ndf['FAVC_clean'] = df['FAVC'].fillna('unknown')\ndf['SMOKE_clean'] = df['SMOKE'].fillna('unknown')\ndf['CALC_clean'] = df['CALC'].fillna('unknown')\n\n\n\n\n3.2.4 Imputing FAF, Weight, TUE, CH2O, Age, NCP, FCVC\n\n\nCode\n# numeric attributes\nnum_attrs = ['FAF','Weight','TUE','CH2O','Age','NCP','FCVC']\n\n# applying mean imputation\nfor attr in num_attrs:\n    new_attr = attr+'_clean'\n    df[new_attr] = df[attr].fillna(df[attr].mean())"
  },
  {
    "objectID": "task-1.html",
    "href": "task-1.html",
    "title": "Bash script to split obesity dataset into seperate files based on gender and weight class",
    "section": "",
    "text": "The task is to divide the obesity dataset provided in obesity.data.txt file into smaller files based on gender and weight class.\n\n1 Script\nThe following script reads the dataset file line by line. For each line, the script does the following\n\nCheck whether the gender is female or male, and based on the result, write the record in a gender-specific data file (e.g., female.data.txt).\nCheck the class label of each record and write the record to a dataset file corresponding to the class label (e.g., overweight).\n\n\n\nprepare.sh\n\nINPUT=obesity.data.txt\n\n# iterating over each line, reading attributes in an array\nwhile IFS=$'\\t' read -ra fields \ndo\n    # compare the first field value\n    if [ \"${fields[0]}\" == \"Female\" ]\n    then\n        echo \"${fields[@]}\" &gt;&gt; female.data.txt\n    else\n        echo \"${fields[@]}\" &gt;&gt; male.data.txt\n    fi\n\n    # access the last element in the record array\n    label=${fields[${#fields[@]} - 1]}\n        \n    # save according to weight class\n    case $label in\n        1)  echo \"${fields[@]}\"  &gt;&gt; class_under_weigth.txt;;\n        2)  echo \"${fields[@]}\" &gt;&gt; class_normal.txt;;\n        3)  echo \"${fields[@]}\" &gt;&gt; class_overweight.txt;;\n        4)  echo \"${fields[@]}\" &gt;&gt; class_obese.txt;;\n    esac\ndone &lt; $INPUT\n\n\n\n2 Execution\nTo run the above script file (i.e., prepare.sh), execute the following command on your terminal. Make sure the dataset file is in the same directory of the script.\nsh prepare.sh"
  },
  {
    "objectID": "task-2.html",
    "href": "task-2.html",
    "title": "Impute missing data",
    "section": "",
    "text": "The task is to impute missing data in the obesity dataset. Data imputation is a set of techniques that replaces missing data in a dataset with a value determined based on the used technique. For example, replacing all missing values with the mean value of a numeric attribute.\nIn the obesity dataset there are missing values in all the attributes except Gender and weightClass.\nThe dataset has both numeric and categorical attributes which have missing values. The type of data conditions the type of data imputation techqinues to use. For example, numeric attributes can be imputed using mean, median; categorical attributes can be imputed by category occurring frequently."
  },
  {
    "objectID": "task-2.html#imputing-height",
    "href": "task-2.html#imputing-height",
    "title": "Impute missing data",
    "section": "1.1 Imputing Height",
    "text": "1.1 Imputing Height\nHeight can be imputed using the mean imputation technique. The average height in the dataset is 1.70. However, looking at Figure 1, it can be seen that there is a difference between the heights of males and females. The average male height is 1.75 while the same for a female is 1.64.\nTherefore, the missing values in the height attribute will be replaced with the mean value of height from the participant’s gender group.\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf_org = pd.read_csv('obesity.data.txt', sep='\\t')\ndf = df_org.copy()\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='Height', y='Gender')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Male/Female Height Distribution\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nData imputation approach used: Mean imputation based on gender.\n\n\n\n\nShow the code\n# code-summary: show imputation code\n\n# height data for male and female\nmale_height = df.loc[df['Gender'] == 'Male','Height']\nfemale_height = df.loc[df['Gender'] == 'Female','Height']\n\n# imputing height data\ndf['Height_clean'] = df['Height']\ndf.loc[(df.Gender=='Male') & (df['Height_clean'].isnull()),['Height_clean']] = male_height.mean()\ndf.loc[(df.Gender=='Female') & (df['Height_clean'].isnull()),['Height_clean']] = female_height.mean()"
  },
  {
    "objectID": "task-2.html#imputing-weight",
    "href": "task-2.html#imputing-weight",
    "title": "Impute missing data",
    "section": "1.2 Imputing Weight",
    "text": "1.2 Imputing Weight\nSimilar to Height, the Weight attribute has a different distribution for males and females. Figure 2 shows the weight distribution for the male and female groups.\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='Weight', y='Gender')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Male/Female Weight Distribution\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nData imputation approach used: Median imputation based on gender.\n\n\n\n\nShow the code\n# height data for male and female\nmale_weight = df.loc[df['Gender'] == 'Male','Weight']\nfemale_weight = df.loc[df['Gender'] == 'Female','Weight']\n\n\ndf['Weight_clean'] = df['Weight']\ndf.loc[(df.Gender=='Male') & (df['Weight_clean'].isnull()),['Weight_clean']] = male_weight.median()\ndf.loc[(df.Gender=='Female') & (df['Weight_clean'].isnull()),['Weight_clean']] = female_weight.median()"
  },
  {
    "objectID": "task-2.html#imputing-age",
    "href": "task-2.html#imputing-age",
    "title": "Impute missing data",
    "section": "1.3 Imputing Age",
    "text": "1.3 Imputing Age\nSimilar to Height, The Age attribute has a different distribution for males and females. Figure 3 shows the age distribution for male and female groups.\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='Age', y='Gender')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: Male/Female Age Distribution\n\n\n\n\n\n\n\nShow the code\n# age data for male and female\nmale_age = df.loc[df['Gender'] == 'Male','Age']\nfemale_age = df.loc[df['Gender'] == 'Female','Age']\n\n\ndf['Age_clean'] = df['Age']\ndf.loc[(df.Gender=='Male') & (df['Age_clean'].isnull()),['Age_clean']] = male_age.median()\ndf.loc[(df.Gender=='Female') & (df['Age_clean'].isnull()),['Age_clean']] = female_age.median()"
  },
  {
    "objectID": "task-2.html#imputing-fcvc",
    "href": "task-2.html#imputing-fcvc",
    "title": "Impute missing data",
    "section": "1.4 Imputing FCVC",
    "text": "1.4 Imputing FCVC\nThe FCVC attribute records participants’ responses to the question Do you usually eat vegetables in your meals?\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='FCVC', y='Gender')\n\nplt.title('Do you usually eat vegetables in your meals?')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Male/Female FCVC Distribution\n\n\n\n\n\n\n\nShow the code\n# fcvc data for male and female\nmale_fcvc = df.loc[df['Gender'] == 'Male','FCVC']\nfemale_fcvc = df.loc[df['Gender'] == 'Female','FCVC']\n\n\ndf['FCVC_clean'] = df['FCVC']\ndf.loc[(df.Gender=='Male') & (df['FCVC_clean'].isnull()),['FCVC_clean']] = male_fcvc.median()\ndf.loc[(df.Gender=='Female') & (df['FCVC_clean'].isnull()),['FCVC_clean']] = female_fcvc.median()"
  },
  {
    "objectID": "task-2.html#imputing-ncp",
    "href": "task-2.html#imputing-ncp",
    "title": "Impute missing data",
    "section": "1.5 Imputing NCP",
    "text": "1.5 Imputing NCP\nThe NCP attribute records participants’ responses to the question How many main meals do you have daily?\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='NCP', y='Gender')\nplt.title('How many main meals do you have daily?')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5: Male/Female NCP Distribution\n\n\n\n\n\n\n\nShow the code\n# fcvc data for male and female\nmale_ncp = df.loc[df['Gender'] == 'Male','NCP']\nfemale_ncp = df.loc[df['Gender'] == 'Female','NCP']\n\n\ndf['NCP_clean'] = df['NCP']\ndf.loc[(df.Gender=='Male') & (df['NCP_clean'].isnull()),['NCP_clean']] = male_ncp.median()\ndf.loc[(df.Gender=='Female') & (df['NCP_clean'].isnull()),['NCP_clean']] = female_ncp.median()"
  },
  {
    "objectID": "task-2.html#imputing-ch2o",
    "href": "task-2.html#imputing-ch2o",
    "title": "Impute missing data",
    "section": "1.6 Imputing CH2O",
    "text": "1.6 Imputing CH2O\nThe CH2O attribute records participants’ responses to the question How much water do you drink daily?\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='CH2O', y='Gender')\nplt.title('How much water do you drink daily?')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6: Male/Female CH2O Distribution\n\n\n\n\n\n\n\nShow the code\n# ch20 data for male and female\nmale_ch20 = df.loc[df['Gender'] == 'Male','CH2O']\nfemale_ch20 = df.loc[df['Gender'] == 'Female','CH2O']\n\n\ndf['CH2O_clean'] = df['CH2O']\ndf.loc[(df.Gender=='Male') & (df['CH2O_clean'].isnull()),['CH2O_clean']] = male_ch20.median()\ndf.loc[(df.Gender=='Female') & (df['CH2O_clean'].isnull()),['CH2O_clean']] = female_ch20.median()"
  },
  {
    "objectID": "task-2.html#imputing-faf",
    "href": "task-2.html#imputing-faf",
    "title": "Impute missing data",
    "section": "1.7 Imputing FAF",
    "text": "1.7 Imputing FAF\nThe CH2O attribute records participants’ responses to the question How often do you have physical activity?\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='FAF', y='Gender')\n\nplt.title('How often do you have physical activity?')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7: Male/Female CH2O Distribution\n\n\n\n\n\n\n\nShow the code\n# faf data for male and female\nmale_faf = df.loc[df['Gender'] == 'Male','FAF']\nfemale_faf = df.loc[df['Gender'] == 'Female','FAF']\n\n\ndf['FAF_clean'] = df['FAF']\ndf.loc[(df.Gender=='Male') & (df['FAF_clean'].isnull()),['FAF_clean']] = male_faf.median()\ndf.loc[(df.Gender=='Female') & (df['FAF_clean'].isnull()),['FAF_clean']] = female_faf.median()"
  },
  {
    "objectID": "task-2.html#imputing-tue",
    "href": "task-2.html#imputing-tue",
    "title": "Impute missing data",
    "section": "1.8 Imputing TUE",
    "text": "1.8 Imputing TUE\nThis attribute records participants’ responses to the question How much time do you use technological devices such as cell phone, videogames, television, computer and others?\n\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# load dataset\ndf = pd.read_csv('obesity.data.txt', sep='\\t')\n\nplt.figure(figsize=(6,4))\n\n# plotting height distribution of male and female\nsns.boxplot(df, x='TUE', y='Gender')\n\nplt.title('How much time do you use technological devices \\n such as cell phone, videogames, television, computer and others?')\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 8: Male/Female TUE Distribution\n\n\n\n\n\n\n\nShow the code\n# tue data for male and female\nmale_tue = df.loc[df['Gender'] == 'Male','TUE']\nfemale_tue = df.loc[df['Gender'] == 'Female','TUE']\n\n\ndf['TUE_clean'] = df['TUE']\ndf.loc[(df.Gender=='Male') & (df['TUE_clean'].isnull()),['TUE_clean']] = male_tue.median()\ndf.loc[(df.Gender=='Female') & (df['TUE_clean'].isnull()),['TUE_clean']] = female_tue.median()"
  },
  {
    "objectID": "task-4.html",
    "href": "task-4.html",
    "title": "Building machine learning model for predicting obesity",
    "section": "",
    "text": "The task is to train a suitable machine learning tool to predict obesity using the dataset and describe performance of the trained model.\nThe task has been divided into the following steps\n\nBuilding data imputer\nBuilding a transformer to convert categorical attributes into numeric using a one-hot-encoder or label encoder\nBuilding a modeling pipeline\nTrain & test different machine learning algorithms: Logistic regression, Decision Tree, and Random Forest\nCheck the performance of selected models on test set\n\n\n\nShow the code\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom sklearn.base import TransformerMixin\n\ndata = pd.read_csv('obesity.data.txt', sep='\\t')\n\nX = data.drop(['WeightClass'], axis=1)\ny = data['WeightClass']\n\n\n\n\nShow the code\n\n\n\n\n\n\n\n\n\n\n\nGender\nAge\nHeight\nWeight\nFHO\nFAVC\nFCVC\nNCP\nCAEC\nSMOKE\nCH2O\nSCC\nFAF\nTUE\nCALC\nMTRANS\n\n\n\n\n0\nFemale\n23.501249\n1.600000\nNaN\nNaN\nno\nNaN\n3.0\nNaN\nno\n2.074048\nno\nNaN\nNaN\nno\nPublic_Transportation\n\n\n1\nMale\n25.000000\n1.790000\n72.000000\nNaN\nNaN\n2.000000\n3.0\nSometimes\nno\n2.000000\nno\n1.000000\nNaN\nSometimes\nPublic_Transportation\n\n\n2\nMale\n18.274358\n1.824655\n58.621349\nNaN\nyes\n2.140840\n4.0\nSometimes\nno\n2.931438\nNaN\n2.000000\n1.164457\nno\nAutomobile\n\n\n3\nFemale\n26.000000\n1.643892\n111.884535\nyes\nyes\n3.000000\nNaN\nSometimes\nno\n2.768141\nno\nNaN\nNaN\nSometimes\nPublic_Transportation\n\n\n4\nMale\nNaN\n1.850000\n115.000000\nno\nNaN\nNaN\nNaN\nSometimes\nNaN\n3.000000\nyes\n1.000000\nNaN\nno\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2106\nMale\n26.015448\n1.829907\n105.436173\nNaN\nyes\n3.000000\n3.0\nNaN\nno\n2.224914\nno\n1.781589\nNaN\nNaN\nPublic_Transportation\n\n\n2107\nMale\n26.774115\n1.755938\n112.287678\nNaN\nyes\n1.428289\nNaN\nSometimes\nno\nNaN\nno\n0.485322\nNaN\nSometimes\nAutomobile\n\n\n2108\nMale\n23.000000\nNaN\n66.000000\nno\nno\n3.000000\n3.0\nNaN\nno\n2.000000\nno\n3.000000\n0.000000\nNaN\nPublic_Transportation\n\n\n2109\nFemale\n23.803904\n1.581527\n78.089575\nyes\nyes\n2.000000\n1.0\nSometimes\nno\n2.000000\nno\nNaN\n0.000000\nno\nPublic_Transportation\n\n\n2110\nMale\nNaN\n1.766975\n118.363376\nyes\nNaN\n2.964319\n3.0\nSometimes\nno\nNaN\nno\nNaN\n1.875023\nSometimes\nAutomobile\n\n\n\n\n2111 rows × 16 columns\n\n\n\n\n\n1 Building data imputer\nThis step applies data imputation techniques to fill in missing values in the dataset. For the numerical attribute, the median value will be used from the corresponding gender group; for the categorical attribute, the most occurring category will be used.\n\n\nShow the code\nclass ObesityDatasetImputer(TransformerMixin):\n    \"\"\"\n        Custom imputer for obesity dataset\n    \"\"\"\n    def __init__(self):\n        \"\"\"Impute missing values.\n        Initialize a dict for storing imputing values for each attribute.\n\n        \"\"\"\n        self.fill = {}\n    def fit(self, X, y=None):\n        \"\"\"\n        This function fit the imputer which basically compute the imputed value for each attribute.\n        \"\"\"\n        for col in X.columns:\n            # skip for attribute with no missing values\n            if X[col].isnull().sum() == 0:\n                continue\n            \n            if X[col].dtype == np.dtype('O'):\n                self.fill[col] = X[col].mode().iloc[0]\n            else:\n                self.fill[col] = {\n                                    'male':X.loc[X['Gender'] == 'Male',col].median(),\n                                    'female':X.loc[X['Gender'] == 'Female',col].median(),\n                                 }\n        return self\n\n    def transform(self, X, y=None):\n        \"\"\"\n        This function applies the imputation.\n        \"\"\"\n        for col in X.columns:\n            # skip for attribute with no missing values\n            if X[col].isnull().sum() == 0:\n                continue\n                \n            if X[col].dtype == np.dtype('O'):\n                X[col] = X[col].fillna(self.fill[col])\n                \n            else:\n                X.loc[(X.Gender=='Male') & (X[col].isnull()),[col]] = self.fill[col]['male']\n                X.loc[(X.Gender=='Female') & (X[col].isnull()),[col]] = self.fill[col]['female']\n        return X\n\n\n\n\nShow the code\n# Testing\nimputer = ObesityDatasetImputer()\n\n# Fitting to training set\nimputer.fit(X)\n\n# applying imputation\nX_imputed = imputer.transform(X)\n\n\n\n\n2 Building transformer\nThe step transforms categorical attributes into numerical ones using one-hot-encoding or label-encoding.\n\n\nShow the code\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nclass FeatureSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    This class buils a feature selector.\n    \"\"\"\n    def __init__(self, columns):\n        self.columns = columns\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return X[self.columns]\n\n\n\n\n3 Building model pipeline to build obesity classifier\nThis step will delve into the machine learning model-building stage. It will start by preparing a model pipeline for model training. Then, the pipeline will be used to train different machine-learning algorithms.\n\n\nShow the code\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\ncateg_attrs = ['Gender','FHO','FAVC','CAEC','SMOKE','SCC','CALC','MTRANS']\nnum_attrs = ['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n\ncategorical_preprocessor = OneHotEncoder()\nnumerical_preprocessor = StandardScaler()\n\npreprocessor = ColumnTransformer(\n    [\n        (\"one-hot-encoder\", categorical_preprocessor, categ_attrs),\n        (\"standard_scaler\", numerical_preprocessor, num_attrs),\n    ]\n)\n\nimputer = ObesityDatasetImputer()\n\n\n\n\nShow the code\ndef train_model(model, param_grid, X, y):\n    \"\"\"\n    This function trains the model on training set, select the best model based \n    on different hyperparameters configurations, and check the performance on validation set.\n    \n    Args:\n        model: machine learning model to train\n        \n        hyper_params: a dictionary containing hyperparameters to search\n        \n        train_X: training dataset\n        \n        train_y: training labels\n    \n        valid_X: validation dataset\n        \n        valid_y: validation dataset\n        \n    Returns:\n        results: dict\n            A dictionary containing best_model and validation performance\n    \"\"\"\n    # build a pipeline\n    \n    # customer imputer\n    imputer = ObesityDatasetImputer()\n    \n    \n    # processors for categorical and numerical attributes\n    categorical_preprocessor = OneHotEncoder()\n    numerical_preprocessor = StandardScaler()\n\n    # applying transformations\n    preprocessor = ColumnTransformer(\n        [\n            (\"one-hot-encoder\", categorical_preprocessor, categ_attrs),\n            (\"standard_scaler\", numerical_preprocessor, num_attrs),\n        ]\n    )\n    \n    preprocess_pipe = Pipeline([\n        ('imputer', imputer),\n        ('preprocessor', preprocessor)\n    ])\n    \n    preprocess_pipe.fit(X)\n    \n    X_ = preprocess_pipe.transform(X)\n    \n    train_X, test_X, train_y, test_y = train_test_split(X_,y)\n    \n    # search best hyperparameter for the model\n    search = GridSearchCV(model, param_grid, n_jobs=2)\n    \n    search.fit(train_X, train_y)\n    \n    best_model = search.best_estimator_\n    best_params = search.best_params_\n    \n    train_per = best_model.score(train_X, train_y)\n    test_per = best_model.score(test_X, test_y)\n    \n    return {'best_model':best_model,\n            'best_params':best_params,\n            'train_per':train_per,\n            'test_per':test_per}\n    \n\n\n\n\n4 Training and evaluating models\nFigure 1 shows the training and test performance of three models: Logistic regression, Decision Tree, and Random Forest.\n\nLogistic regression performed equally during training and testing, achieving 75% accuracy.\nDecision tree improved training performance (87%) but experienced a higher degradation than the logistic regression model (test performance: 78%).\nRandom forest performed close to decision tree, achieving a training performance of 88%, and test performance of 77%.\n\n\n\nShow the code\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nlg = LogisticRegression(solver='newton-cg', max_iter=100)\ndt = DecisionTreeClassifier()\nrd = RandomForestClassifier()\n\n\nlg_params = {'C':[1, 0.1, 0.01, .001]}\ndt_params = {'max_depth':[4,5,6,7,8]}\nrd_params = {'n_estimators':[50,100,150,200],'max_depth':[4,5,6,7,8]}\n\nlg_per = train_model(lg, lg_params, X, y)\ndt_per = train_model(dt, dt_params, X, y)\nrd_per = train_model(rd, rd_params, X, y)\n\nper = pd.DataFrame({'Model':['Logistic Regression','Decision Tree','Random Forest'],\n                   'train':[int(lg_per['train_per']*100),int(dt_per['train_per']*100),int(rd_per['train_per']*100)],\n                   'test':[int(lg_per['test_per']*100),int(dt_per['test_per']*100),int(rd_per['test_per']*100)]})\n\n\n\nShow the code\nplt.title('Training Performance')\nsns.barplot(per, x='Model',y='train')\nplt.ylim([0,100])\nplt.ylabel('Accuracy')\nplt.xlabel('Models')\nplt.show()\n\nplt.title('Test Performance')\nsns.barplot(per, x='Model',y='test')\nplt.ylim([0,100])\nplt.ylabel('Accuracy')\nplt.xlabel('Models')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Train\n\n\n\n\n\n\n\n\n\n\n\n(b) Test\n\n\n\n\n\n\n\nFigure 1: Classification Performance\n\n\n\n\n\n5 Trying a different imputer\nThis step explores a different imputer for categorical attributes that is replacing missing values with a new category ‘unknown’.\n\nRandom Forest model achieved 97% training accuracy and a smaller degradation in test accuaracy (83%).\n\n\n\nShow the code\nclass ObesityDatasetImputer2(TransformerMixin):\n    \"\"\"\n        Custom imputer for obesity dataset\n    \"\"\"\n    def __init__(self):\n        \"\"\"Impute missing values.\n        Initialize a dict for storing imputing values for each attribute.\n\n        \"\"\"\n        self.fill = {}\n    def fit(self, X, y=None):\n        \"\"\"\n        This function fit the imputer which basically compute the imputed value for each attribute.\n        \"\"\"\n        for col in X.columns:\n            # skip for attribute with no missing values\n            if X[col].isnull().sum() == 0:\n                continue\n            \n            if X[col].dtype == np.dtype('O'):\n                self.fill[col] = 'unknown'\n            else:\n                self.fill[col] = {\n                                    'male':X.loc[X['Gender'] == 'Male',col].median(),\n                                    'female':X.loc[X['Gender'] == 'Female',col].median(),\n                                 }\n        return self\n\n    def transform(self, X, y=None):\n        \"\"\"\n        This function applies the imputation.\n        \"\"\"\n        for col in X.columns:\n            # skip for attribute with no missing values\n            if X[col].isnull().sum() == 0:\n                continue\n                \n            if X[col].dtype == np.dtype('O'):\n                X[col] = X[col].fillna(self.fill[col])\n                \n            else:\n                X.loc[(X.Gender=='Male') & (X[col].isnull()),[col]] = self.fill[col]['male']\n                X.loc[(X.Gender=='Female') & (X[col].isnull()),[col]] = self.fill[col]['female']\n        return X\n\n\n\n\nShow the code\n# loading dataset\ndata = pd.read_csv('obesity.data.txt', sep='\\t')\n\nX = data.drop(['WeightClass'], axis=1)\ny = data['WeightClass'] - 1\n\n\n \nimputer = ObesityDatasetImputer2()\nimputer.fit(X)\n\nX_ = imputer.transform(X)\n\ngen_mapping = {'Female':0, 'Male':1}\nmapping1 = {'unknown':-1, 'no':0, 'yes':1}\nmapping2 = {'unknown':-1, 'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3}\nmt_mapping = {'unknown':-1, 'Walking':0, 'Bike':1, 'Motorbike':2, 'Public_Transportation':3, 'Automobile':4}\n\n# transforming categ to num\nX_num = X_\n\n\n\n\nShow the code\nX_num['Gender'] = X_['Gender'].map(gen_mapping)\nX_num['FHO'] = X_['FHO'].map(mapping1)\nX_num['FAVC'] = X_['FAVC'].map(mapping1)\nX_num['SMOKE'] = X_['SMOKE'].map(mapping1)\nX_num['SCC'] = X_['SCC'].map(mapping1)\n\nX_num['CALC'] = X_['CALC'].map(mapping2)\nX_num['CAEC'] = X_['CAEC'].map(mapping2)\n\nX_num['MTRANS'] = X_['MTRANS'].map(mt_mapping)\n\n\n\n\nShow the code\n# train and test split\ntrain_X, test_X, train_y, test_y = train_test_split(X_num, y)\n\n# random forest classifier\nrd = RandomForestClassifier()\n\n\n\ndt = DecisionTreeClassifier()\n\nparams = {'n_estimators':[50,100,150,200,250,300],\n         'max_depth': [3, 5, 7, 10],\n          'min_samples_split': [2,3,4, 5, 10]}\n\n\n\n\n\nShow the code\nfrom sklearn.model_selection import cross_val_score\n\n# searching hyperparameters\n#grid = GridSearchCV(rd, params, cv=5)\n#grid.fit(train_X, train_y)\n#best_model = grid.best_estimator_\n\nscore = cross_val_score(best_model, train_X, train_y)\nprint('Train accuracy:{:.2f}% '.format(best_model.score(train_X, train_y)*100))\nprint('Test accuracy:{:.2f}% '.format(best_model.score(test_X, test_y)*100))\n\n\nTrain accuracy:97.09% \nTest accuracy:83.33% \n\n\n\n\n6 Feature importance\nFigure 2 shows feature importance of obesity data attributes towards classifying weight class.\nFeatures Weight, Age, Height FCVC, NCP were the top-5 most important features.\n\n\nShow the code\nfeature_scores = pd.Series(best_model.feature_importances_, index=train_X.columns).sort_values(ascending=False)\nf, ax = plt.subplots(figsize=(25, 30))\nax = sns.barplot(x=feature_scores, y=feature_scores.index)\nax.set_title(\"Visualize feature scores of the features\")\nax.set_yticklabels(feature_scores.index)\nax.set_xlabel(\"Feature importance score\")\nax.set_ylabel(\"Features\")\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Feature importance\n\n\n\n\n\n\n\n7 Confusion matrix\nFigure 3 shows the confusion matrix of moder’s performance on test data set.\nConcern\n\nThe classifier misclassifies ~27% instances of over weight to normal.\n\n\n\nShow the code\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\ncm = confusion_matrix(best_model.predict(test_X),test_y)\n\ncols = ['under_weight','normal','over_weight','obese']\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cols)\ndisp.plot()\n\n\n\n\n\n\n\n\nFigure 3: Feature importance\n\n\n\n\n\n\n\nShow the code\ntest_y.value_counts()\n\n\nWeightClass\n3    234\n2    137\n1     86\n0     71\nName: count, dtype: int64\n\n\n\n\nShow the code\n24/86\n\n\n0.27906976744186046"
  }
]